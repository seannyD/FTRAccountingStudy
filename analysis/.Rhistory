cbind(
rownames(ranef(mD6)$imputed_semantic_domain),
signif(fixef(mD6)["cult.dist.center"] +
ranef(mD6)$imputed_semantic_domain[,2],3))
summary(m1)
cbind(
rownames(ranef(mD6)$imputed_semantic_domain),
signif(fixef(mD6)["cult.dist.center"] +
ranef(mD6)$imputed_semantic_domain[,2],3))
pdx
ggplot(pdx,
aes(x,y,colour=Domain)) +
geom_line() +
xlab("Cultural Distance") +
ylab("Linguistic similarity")
ggplot(pdx,
aes(x,y,colour=Domain)) +
geom_line() +
xlab("Cultural Distance") +
ylab("Linguistic similarity") +
geom_abline(slope=-0.16,intercept=1)
sjp.lmer(mD6,'eff', show.ci = T)
dom.order = ranef(mD6)$imputed_semantic_domain
dom.order = rownames(dom.order[order(dom.order$cult.dist.center),])
px = sjp.lmer(mD6,'rs.ri', show.ci = T, prnt.plot = F)
pdx = px$plot[[3]]$data
pdx$Domain = factor(pdx$grp, levels = dom.order)
pdx$x = pdx$x *
attr(ling.dom$cult.dist.center,"scaled:scale") +
attr(ling.dom$cult.dist.center,"scaled:center")
pdx$y = pdx$y *
attr(ling.dom$rho.center,"scaled:scale") +
attr(ling.dom$rho.center,"scaled:center")
ggplot(pdx,
aes(x,y,colour=Domain)) +
geom_line() +
xlab("Cultural Distance") +
ylab("Linguistic similarity") +
geom_abline(slope=-0.16,intercept=1)
geom_abline(slope=-0.16,intercept=0.3)
ggplot(pdx,
aes(x,y,colour=Domain)) +
geom_line() +
xlab("Cultural Distance") +
ylab("Linguistic similarity") +
geom_abline(slope=-0.16,intercept=0.3)
ggplot(pdx,
aes(x,y,colour=Domain)) +
geom_line() +
xlab("Cultural Distance") +
ylab("Linguistic similarity") +
geom_abline(slope=-0.16*attr(ling.dom$rho.center,"scaled:scale"),intercept=0.3)
ggplot(pdx,
aes(x,y,colour=Domain)) +
geom_line() +
xlab("Cultural Distance") +
ylab("Linguistic similarity") +
geom_abline(slope=-0.16*attr(ling.dom$cult.dist.center,"scaled:scale"),intercept=0.3)
attr(ling.dom$cult.dist.center,"scaled:scale")
cor(pdx$x[pdx$Domain=="Kinship"],pdx$y[pdx$Domain=="Kinship"])
ggplot(pdx,
aes(x,y,colour=Domain)) +
geom_line() +
geom_point()+
xlab("Cultural Distance") +
ylab("Linguistic similarity")
-0.16*attr(ling.dom$cult.dist.center,"scaled:scale")
-0.16*attr(ling.dom$rho.center,"scaled:scale")
geom_abline(slope=-0.16,intercept=0.3)
ggplot(pdx,
aes(x,y,colour=Domain)) +
geom_line() +
xlab("Cultural Distance") +
ylab("Linguistic similarity") +
geom_abline(slope=-0.16,intercept=0.3)
cbind(
rownames(ranef(mD6)$imputed_semantic_domain),
signif(fixef(mD6)["cult.dist.center"] +
ranef(mD6)$imputed_semantic_domain[,2],3))
print(d)
cbind(
rownames(ranef(mD6)$imputed_semantic_domain),
signif(fixef(mD6)["cult.dist.center"] +
ranef(mD6)$imputed_semantic_domain[,2],3))
ref.slopes.dom = data.frame(
rownames(ranef(mD6)$imputed_semantic_domain),
(fixef(mD6)["cult.dist.center"] +
ranef(mD6)$imputed_semantic_domain[,2],3))
ref.slopes.dom = data.frame(
domain = rownames(ranef(mD6)$imputed_semantic_domain),
slope = (fixef(mD6)["cult.dist.center"] +
ranef(mD6)$imputed_semantic_domain[,2]))
ref.slopes.dom[order(ref.slopes.dom$slope),]
# Download the google sheet:
# https://docs.google.com/spreadsheets/d/1uWWM6Qvn3P5XZYMErD1TalOIMdbv4q2H80bZwdNRauI/edit#gid=0
# And make a json
try(setwd("/Library/WebServer/Documents/Halloween/SGT6/build/map/"))
library(dplyr)
library(googlesheets)
gx = gs_ls()
g = gs_key("1uWWM6Qvn3P5XZYMErD1TalOIMdbv4q2H80bZwdNRauI")
d = g %>% gs_read(ws="map")
d = as.matrix(d)
d[is.na(d)] = ""
getExits = function(i,j){
if(is.na(d[j,i])){
return(list())
}
if(d[j,i]=="Z" || d[j,i]==""){
return(list())
}
exits = list()
if(i<ncol(d) && d[j,i+1] == "X"){
exits[[length(exits)+1]] = c("E",paste0("R",i+2,"X",j))
}
if(i>1 && d[j,i-1] == "X"){
exits[[length(exits)+1]] = c("W",paste0("R",i-2,"X",j))
}
if(j<nrow(d) && d[j+1,i] == "X"){
exits[[length(exits)+1]] = c("S",paste0("R",i,"X",j+2))
}
if(j>1 && d[j-1,i] == "X"){
exits[[length(exits)+1]] = c("N",paste0("R",i,"X",j-2))
}
return(exits)
}
makeRoomJSON = function(roomName,description,exits){
description = paste0('"',
gsub('"',"'",description),
'"')
description = gsub("START:","",description)
paste0(roomName,
":{description:",description,",",
"exits:{",
paste(
sapply(exits,function(X){
paste0(X[1],":",'"',X[2],'"')
}), collapse=','),
"}",
"}"
)
}
roomJSONS = list()
startRooms = c()
for(i in 1:ncol(d)){
for(j in 1:nrow(d)){
roomName = paste0("R",i,"X",j)
exits = getExits(i,j)
if(length(exits)>0){
description = d[j,i]
if(grepl("START:",description)){
startRooms = c(startRooms,roomName)
}
roomJSONS = c(roomJSONS,
makeRoomJSON(roomName,
description,
exits))
}
}
}
mapJSON = paste0("map = {\n",
paste(roomJSONS,collapse=",\n"),
"\n}")
startJSON = paste0("map_start_rooms = [",
paste(shQuote(startRooms),collapse=","),
"]")
cat(paste0(mapJSON,"\n",startJSON),
file="../../lib/map.js")
description = "s jans kdansdn a"
substr(description,nchar(description))
substr(description,nchar(description),nchar(description)+1)
# Download the google sheet:
# https://docs.google.com/spreadsheets/d/1uWWM6Qvn3P5XZYMErD1TalOIMdbv4q2H80bZwdNRauI/edit#gid=0
# And make a json
try(setwd("/Library/WebServer/Documents/Halloween/SGT6/build/map/"))
library(dplyr)
library(googlesheets)
gx = gs_ls()
g = gs_key("1uWWM6Qvn3P5XZYMErD1TalOIMdbv4q2H80bZwdNRauI")
d = g %>% gs_read(ws="map")
d = as.matrix(d)
d[is.na(d)] = ""
getExits = function(i,j){
if(is.na(d[j,i])){
return(list())
}
if(d[j,i]=="Z" || d[j,i]==""){
return(list())
}
exits = list()
if(i<ncol(d) && d[j,i+1] == "X"){
exits[[length(exits)+1]] = c("E",paste0("R",i+2,"X",j))
}
if(i>1 && d[j,i-1] == "X"){
exits[[length(exits)+1]] = c("W",paste0("R",i-2,"X",j))
}
if(j<nrow(d) && d[j+1,i] == "X"){
exits[[length(exits)+1]] = c("S",paste0("R",i,"X",j+2))
}
if(j>1 && d[j-1,i] == "X"){
exits[[length(exits)+1]] = c("N",paste0("R",i,"X",j-2))
}
return(exits)
}
makeRoomJSON = function(roomName,description,exits){
description = paste0('"',
gsub('"',"'",description),
'"')
description = gsub("START:","",description)
if(substr(description,nchar(description),nchar(description)+1)!="."){
description = paste0(description,".")
}
paste0(roomName,
":{description:",description,",",
"exits:{",
paste(
sapply(exits,function(X){
paste0(X[1],":",'"',X[2],'"')
}), collapse=','),
"}",
"}"
)
}
roomJSONS = list()
startRooms = c()
for(i in 1:ncol(d)){
for(j in 1:nrow(d)){
roomName = paste0("R",i,"X",j)
exits = getExits(i,j)
if(length(exits)>0){
description = d[j,i]
if(grepl("START:",description)){
startRooms = c(startRooms,roomName)
}
roomJSONS = c(roomJSONS,
makeRoomJSON(roomName,
description,
exits))
}
}
}
mapJSON = paste0("map = {\n",
paste(roomJSONS,collapse=",\n"),
"\n}")
startJSON = paste0("map_start_rooms = [",
paste(shQuote(startRooms),collapse=","),
"]")
cat(paste0(mapJSON,"\n",startJSON),
file="../../lib/map.js")
# Download the google sheet:
# https://docs.google.com/spreadsheets/d/1uWWM6Qvn3P5XZYMErD1TalOIMdbv4q2H80bZwdNRauI/edit#gid=0
# And make a json
try(setwd("/Library/WebServer/Documents/Halloween/SGT6/build/map/"))
library(dplyr)
library(googlesheets)
gx = gs_ls()
g = gs_key("1uWWM6Qvn3P5XZYMErD1TalOIMdbv4q2H80bZwdNRauI")
d = g %>% gs_read(ws="map")
d = as.matrix(d)
d[is.na(d)] = ""
getExits = function(i,j){
if(is.na(d[j,i])){
return(list())
}
if(d[j,i]=="Z" || d[j,i]==""){
return(list())
}
exits = list()
if(i<ncol(d) && d[j,i+1] == "X"){
exits[[length(exits)+1]] = c("E",paste0("R",i+2,"X",j))
}
if(i>1 && d[j,i-1] == "X"){
exits[[length(exits)+1]] = c("W",paste0("R",i-2,"X",j))
}
if(j<nrow(d) && d[j+1,i] == "X"){
exits[[length(exits)+1]] = c("S",paste0("R",i,"X",j+2))
}
if(j>1 && d[j-1,i] == "X"){
exits[[length(exits)+1]] = c("N",paste0("R",i,"X",j-2))
}
return(exits)
}
makeRoomJSON = function(roomName,description,exits){
description("  +"," ",description)
if(substr(
description,nchar(description),
nchar(description)+1)!="."){
description = paste0(description,".")
}
description = paste0('"',
gsub('"',"'",description),
'"')
description = gsub("START:","",description)
paste0(roomName,
":{description:",description,",",
"exits:{",
paste(
sapply(exits,function(X){
paste0(X[1],":",'"',X[2],'"')
}), collapse=','),
"}",
"}"
)
}
roomJSONS = list()
startRooms = c()
for(i in 1:ncol(d)){
for(j in 1:nrow(d)){
roomName = paste0("R",i,"X",j)
exits = getExits(i,j)
if(length(exits)>0){
description = d[j,i]
if(grepl("START:",description)){
startRooms = c(startRooms,roomName)
}
roomJSONS = c(roomJSONS,
makeRoomJSON(roomName,
description,
exits))
}
}
}
mapJSON = paste0("map = {\n",
paste(roomJSONS,collapse=",\n"),
"\n}")
startJSON = paste0("map_start_rooms = [",
paste(shQuote(startRooms),collapse=","),
"]")
cat(paste0(mapJSON,"\n",startJSON),
file="../../lib/map.js")
getExits = function(i,j){
if(is.na(d[j,i])){
return(list())
}
if(d[j,i]=="Z" || d[j,i]==""){
return(list())
}
exits = list()
if(i<ncol(d) && d[j,i+1] == "X"){
exits[[length(exits)+1]] = c("E",paste0("R",i+2,"X",j))
}
if(i>1 && d[j,i-1] == "X"){
exits[[length(exits)+1]] = c("W",paste0("R",i-2,"X",j))
}
if(j<nrow(d) && d[j+1,i] == "X"){
exits[[length(exits)+1]] = c("S",paste0("R",i,"X",j+2))
}
if(j>1 && d[j-1,i] == "X"){
exits[[length(exits)+1]] = c("N",paste0("R",i,"X",j-2))
}
return(exits)
}
makeRoomJSON = function(roomName,description,exits){
gsub("  +"," ",description)
if(substr(
description,nchar(description),
nchar(description)+1)!="."){
description = paste0(description,".")
}
description = paste0('"',
gsub('"',"'",description),
'"')
description = gsub("START:","",description)
paste0(roomName,
":{description:",description,",",
"exits:{",
paste(
sapply(exits,function(X){
paste0(X[1],":",'"',X[2],'"')
}), collapse=','),
"}",
"}"
)
}
roomJSONS = list()
startRooms = c()
for(i in 1:ncol(d)){
for(j in 1:nrow(d)){
roomName = paste0("R",i,"X",j)
exits = getExits(i,j)
if(length(exits)>0){
description = d[j,i]
if(grepl("START:",description)){
startRooms = c(startRooms,roomName)
}
roomJSONS = c(roomJSONS,
makeRoomJSON(roomName,
description,
exits))
}
}
}
mapJSON = paste0("map = {\n",
paste(roomJSONS,collapse=",\n"),
"\n}")
startJSON = paste0("map_start_rooms = [",
paste(shQuote(startRooms),collapse=","),
"]")
cat(paste0(mapJSON,"\n",startJSON),
file="../../lib/map.js")
library(haven)
library(brms)
setwd("~/Documents/Bristol/FTRAccounting/FTRAccountingStudy/analysis/")
# Curcd: ISO currency code
# Fic: Current ISO country code – country of incorporation
# Loc: Current ISO country code – headquarters
# Country: Country ID from IBES (Thompson Reuters). This database includes financial analysts forecasts information. I attach the table from IBES manual that details the country codes used.
d = read_dta("../data/raw/ftrdataset July 5 2017.dta")
l = read.csv("../data/raw/langftr.csv",
stringsAsFactors = F,encoding = "UTF-8",
fileEncoding = 'UTF-8')
l$genus = gsub(" +$","",l$genus)
l$genus2 = gsub(" +$","",l$genus2)
l$genus3 = gsub(" +$","",l$genus3)
l$genus[l$genus==""] = " None"
l$genus2[l$genus2==""] = " None"
l$genus3[l$genus3==""] = " None"
allGenus = unique(c(l$genus,l$genus2,l$genus3))
allGenus = sort(allGenus)
allGenus.code = 0:length(allGenus)
names(allGenus.code)= allGenus
l$G1 = allGenus.code[l$genus]
l$G2 = allGenus.code[l$genus2]
l$G3 = allGenus.code[l$genus3]
l$G1[is.na(l$G1)] = 0
l$G2[is.na(l$G1)] = 0
l$G3[is.na(l$G1)] = 0
# weights (balanced, but zero if genus is ' None')
l$G1.p = 1/apply(l[,c("G1","G2","G3")],1,function(X){sum(X>0)})
l$G2.p = 1/apply(l[,c("G1","G2","G3")],1,function(X){sum(X>0)})
l$G3.p = 1/apply(l[,c("G1","G2","G3")],1,function(X){sum(X>0)})
d$G1 = l[match(d$loc,l$loc),]$G1
d$G2 = l[match(d$loc,l$loc),]$G2
d$G3 = l[match(d$loc,l$loc),]$G3
d$G1.p = l[match(d$loc,l$loc),]$G1.p
d$G2.p = l[match(d$loc,l$loc),]$G2.p
d$G3.p = l[match(d$loc,l$loc),]$G3.p
head(d)
names(d)
write.csv(d,"../data/clean/data.csv",
row.names = F,
fileEncoding = "utf-8")
d = read.csv("../data/clean/data.csv",
fileEncoding = "utf-8",
encoding = 'utf-8')
dim(d)
d = d[sample(1:nrow(d),2000),]
summary(lm(AAM~ 1 + pcftr, data=d))
fit_mm <-
brm(AAM ~ 1 + pcftr +
(1 | mm(G1, G2, G3, # genuses
weights = cbind(G1.p, G2.p, G3.p))),
data   = d,
warmup = 50,
iter   = 100)
plot(fit_mm)
stanplot((fit_mm))
?brm
save(d,"../data/clean/data_min.Rdat")
mc.cores
getOption("mc.cores")
getOption("mc.cores",1L)
?getOption
library(parallel)
getOption("mc.cores")
library(haven)
library(brms)
setwd("~/Documents/Bristol/FTRAccounting/FTRAccountingStudy/analysis/")
# Curcd: ISO currency code
# Fic: Current ISO country code – country of incorporation
# Loc: Current ISO country code – headquarters
# Country: Country ID from IBES (Thompson Reuters). This database includes financial analysts forecasts information. I attach the table from IBES manual that details the country codes used.
d = read_dta("../data/raw/ftrdataset July 5 2017.dta", encoding = 'utf-8')
l = read.csv("../data/raw/langftr.csv",
stringsAsFactors = F,
encoding = "UTF-8",
fileEncoding = 'UTF-8')
l$genus = gsub(" +$","",l$genus)
l$genus2 = gsub(" +$","",l$genus2)
l$genus3 = gsub(" +$","",l$genus3)
l$genus[l$genus==""] = " None"
l$genus2[l$genus2==""] = " None"
l$genus3[l$genus3==""] = " None"
allGenus = unique(c(l$genus,l$genus2,l$genus3))
allGenus = sort(allGenus)
allGenus.code = 0:length(allGenus)
names(allGenus.code)= allGenus
l$G1 = allGenus.code[l$genus]
l$G2 = allGenus.code[l$genus2]
l$G3 = allGenus.code[l$genus3]
l$G1[is.na(l$G1)] = 0
l$G2[is.na(l$G1)] = 0
l$G3[is.na(l$G1)] = 0
# weights (balanced, but zero if genus is ' None')
l$G1.p = 1/apply(l[,c("G1","G2","G3")],1,function(X){sum(X>0)})
l$G2.p = 1/apply(l[,c("G1","G2","G3")],1,function(X){sum(X>0)})
l$G3.p = 1/apply(l[,c("G1","G2","G3")],1,function(X){sum(X>0)})
d$G1 = l[match(d$loc,l$loc),]$G1
d$G2 = l[match(d$loc,l$loc),]$G2
d$G3 = l[match(d$loc,l$loc),]$G3
d$G1.p = l[match(d$loc,l$loc),]$G1.p
d$G2.p = l[match(d$loc,l$loc),]$G2.p
d$G3.p = l[match(d$loc,l$loc),]$G3.p
write.csv(d,"../data/clean/data.csv",
row.names = F,
fileEncoding = "utf-8")
# Make minimal file for cluster run
d = d[,c("AAM","pcftr","G1","G2","G3","G1.p","G2.p","G3.p")]
save(d,file = "../data/clean/data_min.Rdat")
dim(d)
?brm
?brm
