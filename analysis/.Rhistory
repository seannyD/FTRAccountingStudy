d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,head,n=1),
status = tapply(d$FirstAuthStatus,d$Number,head,n=1),
)
d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,head,n=1),
status = tapply(d$FirstAuthStatus,d$Number,head,n=1)
)
ggplot(d2,aes(x=gender*status,y=score)) + geom_violin()
ggplot(d2,aes(x=gender:status,y=score)) + geom_violin()
ggplot(d2,aes(x=status,y=score)) + geom_violin()
d2$genstatus = paste(d2$gender,d2$status)
ggplot(d2,aes(x=genstatus,y=score)) + geom_violin()
summary(lm(score~gender*status,data=d2))
summary(lm(score~gender+status,data=d2))
hist(d2$score)
d2$genstatus = paste(d2$status,d2$gender)
ggplot(d2,aes(x=genstatus,y=score)) + geom_violin()
ggplot(d2,aes(x=genstatus,y=score)) + geom_violin() + geom_boxplot()
head(d)
d = read.csv("~/Documents/Conferences/Evolang12/genderBias2018/data/E12.csv", stringsAsFactors = F)
d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,head,n=1),
status = tapply(d$FirstAuthStatus,d$Number,head,n=1),
SubmissionLength = tapply(d$SubmissionLength)
)
d2$genstatus = paste(d2$status,d2$gender)
library(ggplot2)
ggplot(d2,aes(x=genstatus,y=score)) + geom_violin() + geom_boxplot()
summary(lm(score~gender*status*SubmissionLength,data=d2))
d = read.csv("~/Documents/Conferences/Evolang12/genderBias2018/data/E12.csv", stringsAsFactors = F)
d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,head,n=1),
status = tapply(d$FirstAuthStatus,d$Number,head,n=1),
SubmissionLength = tapply(d$SubmissionLength,d$Number,head,n=1)
)
d2$genstatus = paste(d2$status,d2$gender)
library(ggplot2)
ggplot(d2,aes(x=genstatus,y=score)) + geom_violin() + geom_boxplot()
summary(lm(score~gender*status*SubmissionLength,data=d2))
summary(lm(score~gender*SubmissionLength,data=d2))
summary(lm(score~gender*status,data=d2))
d3 = read.table("/Users/sgroberts/Documents/MPI/refLexIron/LexDistances/Lesage/IronLingPy/IronWords2/Data/LingPyOutput/SWADESH_POST_lexstat.qlc", sep="\t",header=T,stringsAsFactors = F, fileEncoding = "UTF-8", encoding = "UTF-8",quote='',skip=7)
head(d3)
length(unique(d3$LEXSTATID))
dim(d3)
d2 = read.table("/Users/sgroberts/Documents/MPI/refLexIron/LexDistances/Lesage/IronLingPy/IronWords2/Data/qlc/Swadesh_lexstat.qlc", sep="\t",header=T,stringsAsFactors = F, fileEncoding = "UTF-8", encoding = "UTF-8", skip=81)
unqiue(unlist(strsplit(d2$TOKENS,"")))
unique(unlist(strsplit(d2$TOKENS,"")))
unique(unlist(strsplit(d2$TOKENS[d2$DOCULECT=="XX205"],"")))
a = d2[d2$DOCULECT=="XX205",]
b = d2[d2$DOCULECT=="luoXaa",]
head(a)
head(b)
unique(a$CONCEPT)
unique(b$CONCEPT)
x = intersect(a$CONCEPT,b$CONCEPT)
x
a[a$CONCEPT %in% x,][order(a$CONCEPT),]
a[a$CONCEPT %in% x,][order(a$CONCEPT),]$COUNTERPART
b[b$CONCEPT %in% x,][order(b$CONCEPT),]$COUNTERPART
d3 = read.table("/Users/sgroberts/Documents/MPI/refLexIron/LexDistances/Lesage/IronLingPy/IronWords2/Programs/Python/SWADESH_POST_lexstat_full.qlc", sep="\t",header=T,stringsAsFactors = F, fileEncoding = "UTF-8", encoding = "UTF-8",quote='',skip=7)
d3 = read.table("/Users/sgroberts/Documents/MPI/refLexIron/LexDistances/Lesage/IronLingPy/IronWords2/Programs/Python/SWADESH_POST_lexstat_full.qlc", sep="\t",header=T,stringsAsFactors = F, fileEncoding = "UTF-8", encoding = "UTF-8",quote='',skip=3)
length(unique(d3$DO))
length(unique(d3$LEXSTATID))
dim(d3)
n = 200
noise = 2
a = rnorm(n)
z = rnorm(n)
c = jitter(z,amount = noise)
b = jitter(c+a,amount = noise)
plot(z,c)
n = 200
noise = 2
a = rnorm(n)
z = rnorm(n)
c = jitter(z,amount = noise)
b = jitter(c+a,amount = noise)
plot(z,c)
summary(lm(c~z + a))
cor(z,c)
cor(a,c)
summary(lm(c~z + a))
n = 200
noise = 4
a = rnorm(n)
z = rnorm(n)
c = jitter(z,amount = noise)
b = jitter(c+a,amount = noise)
plot(z,c)
cor(z,c)
cor(a,c)
summary(lm(c~z + a))
summary(lm(c~z + a + b))
summary(lm(c~z + a))
cor(z,c)
cor(a,c)
plot(z,c)
summary(lm(c~z + a))
summary(lm(c~z + a + b))
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + A)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
n=200
err = 2
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter(X + C,amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + A)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
n=200
err = 5
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter(X + C,amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + A)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
n=200
err = 10
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter(X + C,amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + A)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m3 = lm(X ~ Y + C)
summary(m3)
summary(m1)
summary(m3)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m4 = lm(X ~ Y + C)
summary(m4)
n=200
err = 10
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter(X + C,amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + B)
summary(m1)
n=200
err = 10
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter((0.35*X) + (0.65*C),amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + B)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m4 = lm(X ~ Y + C)
summary(m4)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + B)
summary(m1)
m4 = lm(X ~ Y + C)
summary(m4)
n=1000
err = 10
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter((0.35*X) + (0.65*C),amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + B)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m4 = lm(X ~ Y + C)
summary(m4)
hist(X)
hist(Y)
hist(Z)
hist(A)
hist(B)
hist(C)
hist(Y)
mean(Y)
summary(m4)
m4 = lm(X ~ 0 + Y + C)
summary(m4)
m0 = lm(X ~ 0 + Y)
summary(m0)
m1 = lm(X ~ 0 + Y + B)
summary(m1)
m2 = lm(X ~ 0 + Y + A + B)
summary(m2)
cor(X,Y)
cor(X,Y)
n=1000
err = 10
A = rnorm(n) + 10
C = rnorm(n) + 10
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter((0.35*X) + (0.65*C),amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + B)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m4 = lm(X ~ Y + C)
summary(m4)
cor(X,Y)
m1 = lm(X ~ Y + B)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m4 = lm(X ~ Y + C)
summary(m4)
library(devtools)
install_github("jtextor/dagitty/r")
install.packages("devtools")
install.packages("devtools")
library(devtools)
install_github("jtextor/dagitty/r")
library(dagitty)
g <- dagitty("pdag { x[e] y[o] a -- {i z b}; {a z i} -> x -> y <- {z b} }")
plot(g)
?plot(g)
plot.daggity
plot(g)
?graphLayout
graphLayout(g)
plot(graphLayout(g))
adjustmentSets( g )
graphLayout(g)
g <- dagitty("pdag { x[e] y[o] a -- {i z b}; {a z i} -> x -> y <- {z b} }")
plot(graphLayout(g))
adjustmentSets( g )
plot(graphLayout(g))
library(openxlsx)
d = read.xlsx("~/Downloads/countrydata.xlsx",startRow = 4)
head(d)
cont = read.csv("~/Documents/MPI/CausalGraphs/CausalGraphExamples/Diversity/Data/Countries-Continents-csv.csv")
d = read.xlsx("~/Downloads/countrydata.xlsx",startRow = 4)
cont = read.csv("~/Documents/MPI/CausalGraphs/CausalGraphExamples/Diversity/Data/Countries-Continents-csv.csv",stringsAsFactors = F)
d$continent = cont[match(d$Country,cont$Country),]$Continent2
d$continent
d[is.na(d$continent),]
unique(d$continent)
library(openxlsx)
d = read.xlsx("~/Downloads/countrydata.xlsx",startRow = 4)
cont = read.csv("~/Documents/MPI/CausalGraphs/CausalGraphExamples/Diversity/Data/Countries-Continents-csv.csv",stringsAsFactors = F)
d$continent = cont[match(d$Country,cont$Country),]$Continent2
d[d$Country=="Bolivia Plurinational State of",]$continent = "Europe"
d[d$Country=="Korea Republic of",]$continent = "Asia"
d[d$Country=="Venezuela Bolivarian Republic of",]$continent = "South America"
d[d$Country=="Moldova Republic of",]$continent = "Europe"
d[d$Country=="Viet Nam",]$continent = "Asia"
d[d$Country=="Iran Islamic Republic of",]$continent = "Asia"
d[d$Country=="Tanzania United Republic of",]$continent = "East Africa"
d$continent
table(d$continent)
library(lme4)
barplot(d$Country,d$continent)
barplot(d$Rank~d$continent)
d$Rank
d$Rank+1
d$continent
barplot(d$Rank~d$continent)
boxplot(d$Rank~d$continent)
d
sort(d$Country)
library(foreign)
read.spss("~/Desktop/GPS_dataset_country_level/country.dta")
d = read.spss("~/Desktop/GPS_dataset_country_level/country_v11.dta")
d = read.dta("~/Desktop/GPS_dataset_country_level/country.dta")
d = read.dta("~/Desktop/GPS_dataset_country_level/country_v11.dta")
head(d)
library(openxlsx)
d = read.xlsx("~/Downloads/countrydata.xlsx",startRow = 4)
cont = read.csv("~/Documents/MPI/CausalGraphs/CausalGraphExamples/Diversity/Data/Countries-Continents-csv.csv",stringsAsFactors = F)
d$continent = cont[match(d$Country,cont$Country),]$Continent2
d[d$Country=="Bolivia Plurinational State of",]$continent = "Europe"
d[d$Country=="Korea Republic of",]$continent = "Asia"
d[d$Country=="Venezuela Bolivarian Republic of",]$continent = "South America"
d[d$Country=="Moldova Republic of",]$continent = "Europe"
d[d$Country=="Viet Nam",]$continent = "Asia"
d[d$Country=="Iran Islamic Republic of",]$continent = "Asia"
d[d$Country=="Tanzania United Republic of",]$continent = "East Africa"
library(lme4)
boxplot(d$Rank~d$continent)
##
library(foreign)
d2 = read.dta("~/Desktop/GPS_dataset_country_level/country_v11.dta")
d$patience = d2[match(d$country,d2$country),]$patience
match(d$country,d2$country)
d2$country
d$Country
d$patience = d2[match(d$Country,d2$country),]$patience
d$patience
plot(d$patience,d$Rank)
m0 = lmer(patience~Rank + (1|continent),data=d)
summary(m0)
cor.test(d$patience,d$Rank)
summary(lm(d$patience~d$Rank))
summary(m0)
m0 = lmer(patience~Rank + (1+Rank|continent),data=d)
summary(m0)
m0 = lmer(patience~Rank + (1|continent),data=d)
m1 = lmer(patience~Rank + (1+Rank||continent),data=d)
anova(m0,m1)
m0 = lmer(patience~Rank + (1|continent),data=d)
m1 = lmer(patience~Rank + (1+Rank|continent),data=d)
anova(m0,m1)
summary(m1)
library(sjPlot)
sjp.lmer(m1,'re')
plot(d$patience,d$Rank)
boxplot(d$patience~d$continent)
?boxplot
boxplot(d$patience~d$continent,horizontal=T)
boxplot(d$patience~d$continent,horizontal=T,las=2)
boxplot(d$patience~d$continent,horizontal=T,las=2,cex=0.5)
boxplot(d$patience~d$continent,horizontal=T,las=2,mar=c(5,2,2,2))
boxplot(d$patience~d$continent,horizontal=T,las=2,mar=c(5,5,2,2))
par(mar=c(5,5,2,2))
boxplot(d$patience~d$continent,horizontal=T,las=2)
par(mar=c(5,8,2,2))
boxplot(d$patience~d$continent,horizontal=T,las=2)
d$continent2 = d$continent
d$continent2[d$continent2 %in% c("West Africa","North Africa","East Africa","Central Africa")] = "Africa"
d$continent2[d$continent2 %in% c("Central America")] = "South America"
d$continent2[d$continent2 %in% c("Central America")] = "South America"
boxplot(d$Rank~d$continent2)
d$patience = d2[match(d$Country,d2$country),]$patience
par(mar=c(5,8,2,2))
boxplot(d$patience~d$continent,horizontal=T,las=2)
summary(lm(d$patience~d$Rank))
m0 = lmer(patience~Rank + (1|continent2),data=d)
m1 = lmer(patience~Rank + (1+Rank|continent2),data=d)
anova(m0,m1)
m0 = lmer(patience~ + (1|continent2),data=d)
summary(m0)
ranef(m0)
try(setwd("~/Documents/Bristol/FTRAccounting/FTRAccountingStudy/analysis/"))
```
```{r echo=F}
getMEText = function(r,ef, wald=NULL, showWald=F,returnText=T){
AIC = r[2,]$AIC
loglikDiff = signif(diff(r$logLik),2)
chi = round(r$Chisq[2],2)
df = r$`Chi Df`[2]
p = signif(r$`Pr(>Chisq)`[2],2)
wald.text = ""
if(!is.null(wald)){
est = signif(wald[1],2)
stder = signif(wald[2],2)
t = signif(wald[3],2)
wptext = ""
wald.text =  paste("beta = ",est,",")
if(showWald){
if(!is.na(wald[4])){
wptext = paste(", Wald p =",signif(wald[4],2))
}
wald.text = paste("beta = ",est,", std.err = ",stder, ", Wald t = ",t,wptext,';')
}
}
begin = 'There was no significant'
if(p <0.09){
begin = "There was a marginal"
}
if(p < 0.05){
begin = 'There was a significant'
}
if(returnText){
return(paste(begin,ef,"(",wald.text,"log likelihood difference =",
loglikDiff,", df = ",df,", Chi Squared =", chi,", p = ",p,")."))
} else{
return(c(est,loglikDiff,df,chi,p))
}
}
```
# Introduction
Test the relationship between strong/weak FTR and AAM, with and without controls for language family.
# Load libraries
```{r warning=F,message=F}
library(lme4)
library(sjPlot)
library(REEMtree)
library(rpart)
library(rpart.plot)
library(MASS)
library(ggplot2)
library(RColorBrewer)
library(MCMCglmm)
library(ape)
library(caper)
library(stargazer)
```
# Load data
```{r}
d = read.csv("../data/clean/data.csv",
fileEncoding = "utf-8",
encoding = 'utf-8')
```
Match each country to its main language and language family:
```{r}
countryMainLanguageFamily =
read.csv("../data/raw/CountryMainLanguageToLanguageFamily.csv",
stringsAsFactors = F)
d$mainLanguageFamily =
countryMainLanguageFamily[
match(as.character(d$loc),
countryMainLanguageFamily$Country.Code),
]$Family
```
Remove countries with many main language families:
```{r}
d$CountryHasManyMainLanguages = countryMainLanguageFamily[
match(as.character(d$loc),
countryMainLanguageFamily$Country.Code),
]$ManyLanguages=="Y"
d2 = d[!d$CountryHasManyMainLanguages,]
d2 = d2[!is.na(d2$AAM),]
```
Remove cases with missing data:
```{r}
keyVar = c("invpro","pd","indiv","mas",
"ua","lto","indul","ggr","SIZE",
"BTM","LEV","ROA","MEET","LOSS")
d2 = d2[complete.cases(d2[,keyVar,]),]
```
Table of languages:
```{r}
data.frame(
tapply(d2$strongftr,as.character(d2$loc),head,n=1)
)
```
Convert to factors:
```{r}
d2$mainLanguageFamily = factor(d2$mainLanguageFamily)
d2$MEET = factor(d2$MEET)
d2$LOSS = factor(d2$LOSS)
d2$strongftr = factor(d2$strongftr)
```
Scale varaibles:
```{r}
d2Orig = d2
# Take log of AAM
d2$logAAM = log(1+d2$AAM)
#d2$logAAM = d2$logAAM - median(d2$logAAM,na.rm = T)
# Scale and center continuous variables
for(v in c("pd",'indiv','mas',
'ua','lto','indul','ggr',
'SIZE',"BTM","LEV","ROA")){
d2[,v] = scale(d2[,v])
}
d2$AAM.scaled = scale(d2$AAM)
```
write.csv("~/Desktop/FTR_finalDataset.csv",row.names = F,fileEncoding = 'UTF-8')
write.csv(d2,"~/Desktop/FTR_finalDataset.csv",row.names = F,fileEncoding = 'UTF-8')
cols = c("AAM.scaled" , "strongftr" ,
"invpro" ,
"pd" , "indiv" , "mas" , "ua" ,"lto" , "indul",
"ggr",
"SIZE" , "BTM" ,"LEV" , "ROA" ,
"MEET", "LOSS","mainLanguageFamily",'gvkey','loc','fyear')
write.csv(d2[,cols],"~/Desktop/FTR_finalDataset.csv",row.names = F,fileEncoding = 'UTF-8')
